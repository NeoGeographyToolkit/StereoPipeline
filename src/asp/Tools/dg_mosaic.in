#!/usr/bin/env python
# __BEGIN_LICENSE__
#  Copyright (c) 2009-2013, United States Government as represented by the
#  Administrator of the National Aeronautics and Space Administration. All
#  rights reserved.
#
#  The NGT platform is licensed under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance with the
#  License. You may obtain a copy of the License at
#  http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
# __END_LICENSE__

# To do: There is no need to round the corners of the images
# which are combined into the mosaic. May improve accuracy
# that way. This change would need very careful testing.

import os, sys, string, subprocess, math, re, optparse, time, copy, tempfile
from datetime import datetime, timedelta
libexec_path = sys.path[0] + '/../libexec'
sys.path.insert(0, libexec_path) # prepend to Python path
from stereo_utils import * # must be after the path is altered above

# Prepend to system PATH
os.environ["PATH"] = libexec_path + os.pathsep + os.environ["PATH"]

def format_microsec(microsec):
    # Ensure that we have 6 digits in a microsecond. Pre-pad with
    # zeros if necessary.
    if len(microsec) > 6:
        raise Exception('InputError', "The microsecond value: " + microsec
                        + " has more than 6 digits.")

    microsec  = (6 - len(microsec)) * '0' + microsec
    return microsec

try:
    import xml.etree.ElementTree as ET
except ImportError:
    # python 2.4
    import elementtree.ElementTree as ET

if hasattr(datetime, 'strptime'):
    def parse_time(date_string, fmt):
        return datetime.strptime(date_string, fmt)
else:
    # python 2.4
    def parse_time(date_str, fmt):
        m = re.match('^(.*?)T(.*?)\.(\d+)Z', date_str)
        if m:
            date_str  = m.group(1) + " " + m.group(2)
            microsec  = format_microsec(m.group(3))
        else:
            raise Exception('InputError', "Could not match string: " + date_str)

        m = re.match('^(.*?)T(.*?)\.(.*?)Z', fmt)
        if m:
            fmt = m.group(1) + " " + m.group(2)
        else:
            raise Exception('InputError', "Could not match string: " + fmt)

        parsed = datetime(*(time.strptime(date_str, fmt)[0:6]))
        parsed = parsed.replace(microsecond=int(microsec))

        return parsed

class Usage(Exception):
    def __init__(self, msg):
        self.msg = msg

# We assume that the boxes are products of closed intervals, [a, b] x
# [c, d]. As such, the box [0, 0] x [0, 0] of width 0 is not empty.
class BBox:
    def __init__(self,
                 minx =  sys.float_info.max, miny =  sys.float_info.max,
                 maxx = -sys.float_info.max, maxy = -sys.float_info.max):
        self.minx = minx
        self.miny = miny
        self.maxx = maxx
        self.maxy = maxy

    def empty(self):
        return ( self.maxx < self.minx ) or ( self.maxy < self.miny )

    def expand_with_box(self, box):
        if box.empty(): return
        if self.empty():
            self.minx = box.minx
            self.miny = box.miny
            self.maxx = box.maxx
            self.maxy = box.maxy
            return
        if box.minx < self.minx: self.minx = box.minx
        if box.miny < self.miny: self.miny = box.miny
        if box.maxx > self.maxx: self.maxx = box.maxx
        if box.maxy > self.maxy: self.maxy = box.maxy

    def add_point(self, pt):
        self.expand_with_box(BBox(pt[0], pt[1], pt[0], pt[1]))

    def extend (self, val):
        # Note: val can be negative
        if self.empty(): return
        self.minx = self.minx - val
        self.miny = self.miny - val
        self.maxx = self.maxx + val
        self.maxy = self.maxy + val
        if self.empty():
            # Ensure all empty boxes are identical. For some reason
            # the line self = BBox() does not work.  So need to assign
            # the members one by one.
            b = BBox()
            self.minx = b.minx
            self.miny = b.miny
            self.maxx = b.maxx
            self.maxy = b.maxy

    def width(self):
        if self.empty(): return 0
        return self.maxx - self.minx

    def height(self):
        if self.empty(): return 0
        return self.maxy - self.miny

    def __repr__(self):
        return "BBox %f %f -> %f %f" % (self.minx,self.miny,self.maxx,self.maxy)

# Create an object made of a string, a 2D vector, and a box. Sort an
# array of such objects by the min coordinate of the box.
class StVecBox:
    def __init__(self, st, vec, box):
        self.st  = st
        self.vec = vec
        self.box = box
def minyCompare(P, Q):
    return P.box.miny - Q.box.miny
def sort_by_miny(args, orig_sizes, placements):
    S = []
    for i in range(len(args)):
        S.append(StVecBox(copy.deepcopy(args[i]),
                          copy.deepcopy(orig_sizes[i]),
                          copy.deepcopy(placements[i])))
    S.sort(minyCompare)
    s_args = []; s_orig_sizes = []; s_placements = []
    for i in range(len(S)):
        s_args.append(S[i].st)
        s_orig_sizes.append(S[i].vec)
        s_placements.append(S[i].box)
    return (s_args, s_orig_sizes, s_placements)

def set_or_wipe_image_tags(IMAGE, avg_meangsd):

    # Wipe most image tags as they differ from image to image. Set the
    # MEANPRODUCTGSD tag as the average of individual values of this
    # tag.

    keep_tags = set(["SATID", "MODE", "SCANDIRECTION", "CATID", "TLCTIME",
                     "NUMTLC", "TLCLISTList", "FIRSTLINETIME", "AVGLINERATE",
                     "EXPOSUREDURATION", "MEANPRODUCTGSD", "CLOUDCOVER",
                     "RESAMPLINGKERNEL", "POSITIONKNOWLEDGESRC",
                     "ATTITUDEKNOWLEDGESRC", "REVNUMBER"]);

    # First store the tags, before we start wiping them
    tags = []
    for i in range(len(IMAGE)):
        tag = IMAGE[i].tag
        tags.append(tag)

    for tag in tags:
        if not tag in keep_tags:
            IMAGE.remove( IMAGE.find (tag) )

    IMAGE.find("MEANPRODUCTGSD").text = str(avg_meangsd)

def adjust_camera_corners(BAND_P, all_ll_corners):

    # The lon-lat box for the combined camera is the union of the
    # lon-lat boxes for all the cameras.

    # Wipe unneeded tags. For that, first store the tags, then wipe
    # them.
    wipe_tags = set(["ULHAE", "URHAE","LRHAE","LLHAE"]);
    tags = []
    for i in range(len(BAND_P)):
        tag = BAND_P[i].tag
        tags.append(tag)
    for tag in tags:
        if tag in wipe_tags:
            BAND_P.remove( BAND_P.find (tag) )

    # Each camera has 4 corners, which are arbitrarily placed.  Find
    # the average of all corners over all cameras. This will be the
    # center. Look at all cameras' LL corner. The one furthest from
    # the center will be the new LL corner. Same for LR, UL, and UR.
    cx = 0
    cy = 0
    np = 0
    for corner_vec in all_ll_corners:
        for corner in corner_vec:
            cx = cx + corner[0]
            cy = cy + corner[1]
            np = np + 1
    cx = cx/np
    cy = cy/np

    out_corners = []
    for i in range(4):
        dist = -1
        cr   = [0, 0]
        for corner_vec in all_ll_corners:
            pt = corner_vec[i]
            ldist = math.sqrt((pt[0]-cx)**2 + (pt[1] - cy)**2)
            if ldist > dist:
                cr   = pt
                dist = ldist
        out_corners.append(cr)

    BAND_P.find("ULLON").text = str(out_corners[0][0])
    BAND_P.find("ULLAT").text = str(out_corners[0][1])

    BAND_P.find("URLON").text = str(out_corners[1][0])
    BAND_P.find("URLAT").text = str(out_corners[1][1])

    BAND_P.find("LRLON").text = str(out_corners[2][0])
    BAND_P.find("LRLAT").text = str(out_corners[2][1])

    BAND_P.find("LLLON").text = str(out_corners[3][0])
    BAND_P.find("LLLAT").text = str(out_corners[3][1])

# Provide the image files that make up the composite. We assume the XML
# files are in the same directory and end with extension ".xml" or ".XML".
def read_xml( filename, options):

    tree = ET.parse( filename )
    root = tree.getroot()
    IMD  = root.find("IMD")
    GEO  = root.find("GEO")
    EPH  = root.find("EPH")
    ATT  = root.find("ATT")
    RPB  = root.find("RPB")

    IMAGE = IMD.find("IMAGE")
    tlctime = parse_time(IMAGE.find("TLCTIME").text.strip(),
                         "%Y-%m-%dT%H:%M:%S.%fZ")
    tlclist = []
    for tlc_item in IMAGE.find("TLCLISTList").findall("TLCLIST"):
        tokens = tlc_item.text.strip().split(' ')
        tlclist.append([float(tokens[0]), float(tokens[1])])
    if len(tlclist) == 1:
        direction = 1.0
        if IMAGE.find("SCANDIRECTION").text.lower() != "forward":
            direction = -1.0
        linerate = float(IMAGE.find("AVGLINERATE").text)
        tlclist.append([(linerate+tlclist[0][0]), (tlclist[0][1]+direction)])
    firstlinetime = parse_time(IMAGE.find("FIRSTLINETIME").text,
                               "%Y-%m-%dT%H:%M:%S.%fZ")

    meangsd = float(IMAGE.find("MEANPRODUCTGSD").text)

    image_size = []
    image_size.append( int(IMD.find("NUMCOLUMNS").text) )
    image_size.append( int(IMD.find("NUMROWS").text) )

    llbox = BBox()
    htbox = BBox()
    ll_corners = []

    # The longitude-lattitude box. Note: Later when we create
    # the adjusted box we will traverse the corners in
    # exactly the same order as here, so this and that
    # code blocks must be kept consistent.
    try:
        ullon = float(IMD.find("BAND_P").find("ULLON").text)
        ullat = float(IMD.find("BAND_P").find("ULLAT").text)
        llbox.add_point([ullon, ullat])
        ll_corners.append([ullon, ullat])

        urlon = float(IMD.find("BAND_P").find("URLON").text)
        urlat = float(IMD.find("BAND_P").find("URLAT").text)
        llbox.add_point([urlon, urlat])
        ll_corners.append([urlon, urlat])

        lrlon = float(IMD.find("BAND_P").find("LRLON").text)
        lrlat = float(IMD.find("BAND_P").find("LRLAT").text)
        llbox.add_point([lrlon, lrlat])
        ll_corners.append([lrlon, lrlat])

        lllon = float(IMD.find("BAND_P").find("LLLON").text)
        lllat = float(IMD.find("BAND_P").find("LLLAT").text)
        llbox.add_point([lllon, lllat])
        ll_corners.append([lllon, lllat])
    except Exception, e:
        raise Exception('InputError', "File " + filename
                        + " lacks longitude/lattitude information.")

    if not options.skip_rpc_gen:
        # The height range, [ht_min, ht_max]. We store it as a 2D box
        # as to not create an interval class.
        try:
            ht_scale = float(RPB.find("IMAGE").find("HEIGHTSCALE").text)
            ht_offset = float(RPB.find("IMAGE").find("HEIGHTOFFSET").text)
            min_ht = -ht_scale + ht_offset
            max_ht =  ht_scale + ht_offset
            htbox = BBox(min_ht, min_ht, max_ht, max_ht)
        except Exception, e:
            raise Exception('InputError', "File " + filename
                            + " lacks RPC model information.")

    DET_ARRAY = GEO.find("DETECTOR_MOUNTING").find("BAND_P").find("DETECTOR_ARRAY")
    pitch     = float(DET_ARRAY.find("DETPITCH").text)
    originx   = DET_ARRAY.find("DETORIGINX").text
    pd        = GEO.find("PRINCIPAL_DISTANCE").find("PD").text

    # Note: We concatenate all eph values into one single array,
    # the proper structure would be an array of arrays.
    eph_list = []
    for eph_item in EPH.find("EPHEMLISTList").findall("EPHEMLIST"):
        tokens = eph_item.text.strip().split(' ')
        eph_list.extend(tokens)

    # Note: We concatenate all att values into one single array,
    # the proper structure would be an array of arrays.
    att_list = []
    for att_item in ATT.find("ATTLISTList").findall("ATTLIST"):
        tokens = att_item.text.strip().split(' ')
        att_list.extend(tokens)

    return [tlctime, tlclist, firstlinetime, image_size, pitch,
            originx, pd, eph_list, att_list, llbox, htbox, ll_corners, meangsd]

def tlc_time_lookup( tlctime, tlclist, pixel_y ):
    fraction = (pixel_y - tlclist[0][0]) / (tlclist[1][0] - tlclist[0][0])
    seconds_off = fraction * ( tlclist[1][1] - tlclist[0][1]) + tlclist[0][1]
    return tlctime + timedelta(seconds=seconds_off)

def tlc_pixel_lookup( tlctime, tlclist, time ):
    difference = time - tlctime
    seconds_since_ref = difference.microseconds /  10.0**6 + difference.seconds + difference.days*24.0*3600.0
    fraction = ( seconds_since_ref - tlclist[0][1] ) / (tlclist[1][1] - tlclist[0][1]);
    return fraction * ( tlclist[1][0] - tlclist[0][0] ) + tlclist[0][0]

# Get the xml file name from the .ntf or .tif file name. The xml file
# must exist and end in either '.xml' or '.XML'.
def xml_name( filename ):

    path, ext = os.path.splitext(filename)
    xml_file_l = path + ".xml"
    xml_file_u = path + ".XML"

    if os.path.isfile(xml_file_l):
        xml_file = xml_file_l
    elif os.path.isfile(xml_file_u):
        xml_file = xml_file_u
    else:
        raise Exception('InputError', 'Cannot find any of: '
                        + xml_file_l + ' ' + xml_file_u)

    return xml_file

def run_cmd( cmd, options ):
    if options.dryrun or options.verbose: print cmd
    if options.dryrun: return
    code = subprocess.call(cmd, shell=True)
    if code:
        raise Exception('ProcessError', 'Non zero return code ('+str(code)+')')

def die(msg, code=-1):
    print >>sys.stderr, msg
    sys.exit(code)

def scale_xml_element(elem, scale):
    tokens = elem.text.strip().split(' ')
    for i in range(len(tokens)):
        tokens[i] = str(float(tokens[i]) * scale)
    elem.text = " ".join(tokens)

def main():

    try:
        try:
            usage = '''dg_mosaic [--help][--gdal-dir dir] <all ntf or tif files that make up the observation>

  [ASP [@]ASP_VERSION[@]]'''

            parser = optparse.OptionParser(usage=usage)
            parser.set_defaults(dryrun=False)
            parser.set_defaults(preview=False)
            parser.set_defaults(gdaldir="")
            parser.set_defaults(reduce_percent=100.0)
            parser.set_defaults(output_prefix="")
            parser.add_option("--gdal-dir", dest="gdaldir",
                              help="Directory where the GDAL tools are. If not provided, we get them from the environment.")
            parser.add_option("--reduce-percent", dest="reduce_percent", type="float",
                              help="Render a reduced resolution image and xml based on this percentage.")
            parser.add_option("--output-prefix", dest="output_prefix", type="str",
                              help="The prefix for the output .tif and .xml files.")
            parser.add_option('--skip-rpc-gen', dest='skip_rpc_gen', default=False,
                              action='store_true', help="Skip RPC model generation")
            parser.add_option("--rpc-penalty-weight", dest="penalty_weight", type="float",
                              default=0.1,
                              help="The weight to use to penalize higher order RPC coefficients when generating the combined RPC model. Higher penalty weight results in smaller such coefficients.")
            parser.add_option("--preview", dest="preview",
                              action="store_true",
                              help="Render a small 8 bit png of the input for preview.")
            parser.add_option("-n", "--dry-run", dest="dryrun",
                              action="store_true",
                              help="Make the calculations, but just print out the commands.")
            parser.add_option("-v", "--verbose", dest="verbose",
                              action="store_true", help="Increase verbosity.")
            # Debug option. Skip the part where we create the tif file,
            # that is quite time-consuming.
            parser.add_option('--skip-tif-gen', dest='skip_tif_gen', default=False,
                              action='store_true', help=optparse.SUPPRESS_HELP)

            (options, args) = parser.parse_args()

            # Transform 50.0 into just 50
            if options.reduce_percent == int(options.reduce_percent):
                options.reduce_percent = int(options.reduce_percent)

            if not args:
                parser.print_help()
                die('\nERROR: Need .ntf or .tif files.', code=2)

            if len(options.gdaldir): options.gdaldir += "/"

        except optparse.OptionError, msg:
            raise Usage(msg)

        if options.output_prefix == "":
            options.output_prefix = args[0].split('-')[-1].split('.')[0]
        if options.output_prefix == "":
            die('\nERROR: Empty output prefix. Please set it via the ' + \
                '--output-prefix option', code=2)
        out_dir=os.path.dirname(options.output_prefix)
        if len(out_dir)==0: out_dir='.'
        if not os.path.exists(out_dir): os.mkdir(out_dir)

        all_ll_corners = []

        # We reference everything from the perspective of the first
        # image. So lets load it up first into our special variables.
        [ref_tlctime, ref_tlclist, ref_firstlinetime, ref_image_size,
         ref_pitch, ref_originx, ref_pd, ref_eph_list, ref_att_list,
         ref_llbox, ref_htbox, ll_corners, avg_meangsd] \
         = read_xml( xml_name(args[0]), options )
        num_gsd = 1
        all_ll_corners.append(ll_corners)

        # orig_sizes[i] holds the original size of i-th image. After
        # we scale i-th image by i_th_image_pitch/0_th_image_pitch, we
        # store the new image box in placements[i].
        orig_sizes = []
        placements = []
        orig_sizes.append(ref_image_size)
        shiftx = 0
        shifty = int(round(tlc_pixel_lookup( ref_tlctime, ref_tlclist,
                                             ref_firstlinetime)))
        placement = BBox(shiftx, shifty,
                         shiftx + ref_image_size[0], shifty + ref_image_size[1])
        placements.append( placement )

        for filename in args[1:]:

            [tlctime, tlclist, firstlinetime, image_size, pitch, originx, pd,
             eph_list, att_list, llbox, htbox, ll_corners, meangsd] \
             = read_xml( xml_name(filename), options )
            all_ll_corners.append(ll_corners)

            # Sanity checks
            if ref_originx != originx:
                raise Exception('InputError', 'Must have the same originx in: '
                                + xml_name(args[0]) + ' ' + xml_name(filename) )
            if ref_pd != pd:
                raise Exception('InputError', 'Must have the same pd in: '
                                + xml_name(args[0]) + ' ' + xml_name(filename) )
            if ref_eph_list != eph_list:
                raise Exception('InputError', 'Must have the same ephem in: '
                                + xml_name(args[0]) + ' ' + xml_name(filename) )
            if ref_att_list != att_list:
                raise Exception('InputError', 'Must have the same att in: '
                                + xml_name(args[0]) + ' ' + xml_name(filename) )

            orig_sizes.append(image_size)
            pitch_ratio = pitch/ref_pitch
            scaled_image_size = [int(round(image_size[0]*pitch_ratio)),
                                 int(round(image_size[1]*pitch_ratio))]
            shiftx = 0
            shifty = int(round(tlc_pixel_lookup(ref_tlctime, ref_tlclist,
                                                firstlinetime)))
            placement = BBox(shiftx, shifty,
                             shiftx + scaled_image_size[0],
                             shifty + scaled_image_size[1])
            placements.append( placement )

            ref_llbox.expand_with_box(llbox)
            ref_htbox.expand_with_box(htbox)

            avg_meangsd = avg_meangsd + meangsd
            num_gsd = num_gsd + 1

        avg_meangsd = avg_meangsd/num_gsd

        boundary = BBox()
        for placement in placements:
            boundary.expand_with_box(placement)

        print "Output image size: %ix%i px" % (boundary.width(),boundary.height())
        for i in range(len(args)):
            placements[i].miny -= boundary.miny
            placements[i].maxy -= boundary.miny

        # Dummy check: Look for duplicate files that will insert at
        # same location. Files that do this would be the R?C1 variants
        # that have the same XML file due to download errors or
        # simplying mixing of R?C1 and the other format.
        seen = set()
        for i in range(len(args)):
            if placements[i].miny in seen:
                raise Exception('InputError', 'Input images have same input location which could be caused by repeated XML file or invalid TLC information')
            seen.add(placements[i].miny)

        scale = options.reduce_percent / 100.0
        suffix = ".r" + str(options.reduce_percent)

        # Write a composite scaled XML file. We first create the xml at
        # the original resolution and then we scale it.
        tree = ET.parse(xml_name(args[0]))
        root = tree.getroot()
        imd = root.find("IMD")
        imd.find("NUMROWS").text = str(boundary.height())
        imd.find("NUMCOLUMNS").text = str(boundary.width())
        for tlc_item in imd.find("IMAGE").find("TLCLISTList").findall("TLCLIST"):
            tokens = tlc_item.text.strip().split(' ')
            tokens[0] = str(int(round((float(tokens[0])))) - boundary.miny)
            tlc_item.text = " ".join(tokens)
        first_line_item = root.find("IMD").find("IMAGE").find("FIRSTLINETIME")
        tlc_lookup = tlc_time_lookup( ref_tlctime, ref_tlclist, boundary.miny )
        # The verbose operation below is needed for python 2.4
        first_line_item.text = tlc_lookup.strftime("%Y-%m-%dT%H:%M:%S") + '.' \
                               + format_microsec(str(tlc_lookup.microsecond)) + "Z"

        if not options.skip_rpc_gen:
            # Find the best-fitting RPC coefficients.
            temp_xml_file = tempfile.NamedTemporaryFile(suffix = ".xml", dir = ".");
            tree.write(temp_xml_file.name)
            rpc_cmd = "rpc_gen"
            rpc_args = ['--penalty-weight', str(options.penalty_weight),
                        '--lon-lat-height-box',
                        str(ref_llbox.minx), str(ref_llbox.miny),
                        str(ref_htbox.minx), str(ref_llbox.maxx),
                        str(ref_llbox.maxy), str(ref_htbox.maxx), temp_xml_file.name]
            rpc_model = run_and_parse_output( rpc_cmd, rpc_args, options.verbose )
            try:
                # Set the RPC model info. Wipe all other outdated info.
                RPI = root.find("RPB").find("IMAGE")
                if RPI.find("ERRBIAS") != None: RPI.remove( RPI.find ("ERRBIAS") )
                if RPI.find("ERRRAND") != None: RPI.remove( RPI.find ("ERRRAND") )

                RPI.find("SAMPSCALE").text    = rpc_model["xy_scale"][0]
                RPI.find("LINESCALE").text    = rpc_model["xy_scale"][1]

                RPI.find("SAMPOFFSET").text   = rpc_model["xy_offset"][0]
                RPI.find("LINEOFFSET").text   = rpc_model["xy_offset"][1]

                RPI.find("LONGSCALE").text    = rpc_model["llh_scale"][0]
                RPI.find("LATSCALE").text     = rpc_model["llh_scale"][1]
                RPI.find("HEIGHTSCALE").text  = rpc_model["llh_scale"][2]

                RPI.find("LONGOFFSET").text   = rpc_model["llh_offset"][0]
                RPI.find("LATOFFSET").text    = rpc_model["llh_offset"][1]
                RPI.find("HEIGHTOFFSET").text = rpc_model["llh_offset"][2]

                RPI.find("LINENUMCOEFList").find("LINENUMCOEF").text = " ".join(rpc_model["line_num"])
                RPI.find("LINEDENCOEFList").find("LINEDENCOEF").text = " ".join(rpc_model["line_den"])
                RPI.find("SAMPNUMCOEFList").find("SAMPNUMCOEF").text = " ".join(rpc_model["samp_num"])
                RPI.find("SAMPDENCOEFList").find("SAMPDENCOEF").text = " ".join(rpc_model["samp_den"])
            except Exception, e:
                raise Exception('InputError', "File " + args[0] +
                                " lacks complete RPC model information.")
        else:
            if root.find("RPB") != None: root.remove( root.find ("RPB") )

        # Wipe other outdated info
        if root.find("TIL")   != None: root.remove( root.find("TIL") )
        if imd.find("BAND_P") != None:
            adjust_camera_corners(imd.find("BAND_P"), all_ll_corners)
        set_or_wipe_image_tags(root.find("IMD").find("IMAGE"), avg_meangsd)

        # Scale the xml file
        # Update NumRows and NumColumns
        imd = root.find("IMD")
        imd.find("NUMROWS").text = str( int(boundary.height() * scale) )
        imd.find("NUMCOLUMNS").text = str( int(boundary.width() * scale) )
        # Update TLCList, AVGLineRate, ExposureDur
        image = imd.find("IMAGE")
        for tlc_item in image.find("TLCLISTList").findall("TLCLIST"):
            tokens = tlc_item.text.strip().split(' ')
            tokens[0] = str(float(tokens[0]) * scale)
            tlc_item.text = " ".join(tokens)
        scale_xml_element(image.find("AVGLINERATE"), scale)
        scale_xml_element(image.find("EXPOSUREDURATION"), 1.0/scale)
        # Update Detector Pitch
        pitch = root.find("GEO").find("DETECTOR_MOUNTING").find("BAND_P").find("DETECTOR_ARRAY").find("DETPITCH")
        scale_xml_element(pitch, 1.0/scale)
        # Scale the RPC model
        if not options.skip_rpc_gen:
            RPI = root.find("RPB").find("IMAGE")
            scale_xml_element(RPI.find("SAMPSCALE"), scale)
            scale_xml_element(RPI.find("LINESCALE"), scale)
            scale_xml_element(RPI.find("SAMPOFFSET"), scale)
            scale_xml_element(RPI.find("LINEOFFSET"), scale)

        xml_file = options.output_prefix + suffix + ".xml"
        print "Writing: " + xml_file
        tree.write(xml_file)

        if not options.skip_tif_gen:
            # Ensure that the images are placed in order, from top to
            # bottom.  So the second image will partially cover the first
            # image, etc.  This is a bug fix for the situation when some
            # images have a black area at the bottom.
            (s_args, s_orig_sizes, s_placements) = \
                     sort_by_miny(args, orig_sizes, placements)

            tif_mosaic_opts = "%d,%d," % (boundary.width(), boundary.height())
            for i in range(len(s_args)):
                print "  Placing %s" % s_args[i]
                print "    Size %ix%i at column %i and line %i" % \
                      (s_placements[i].width(),s_placements[i].height(),
                       s_placements[i].minx, s_placements[i].miny)

                tif_mosaic_opts += ("%s,%0.16f,%0.16f,%0.16f,%0.16f,%0.16f,%0.16f," %
                                    ( os.path.abspath(s_args[i]),
                                      s_orig_sizes[i][0], s_orig_sizes[i][1],
                                      s_placements[i].minx, s_placements[i].miny,
                                      s_placements[i].width(), s_placements[i].height() ) )

            tif_file = options.output_prefix + suffix + ".tif";
            mosaic_cmd = "tif_mosaic"
            mosaic_args = ['--threads', str(4),
                           '--output-image', tif_file,
                           '--reduce-percent', str(options.reduce_percent),
                           '--image-data', tif_mosaic_opts]
            print "Writing: " + tif_file
            run_and_parse_output( mosaic_cmd, mosaic_args, options.verbose )

            # Make a preview image
            if options.preview:

                # The preview image size will be around 5% of the input image size.
                small_scale = int(round(5.0/scale))

                stif_file = options.output_prefix + ".small.png"
                print "Writing: " + stif_file
                cmd = "GDAL_CACHEMAX=256 %sgdal_translate -of PNG -ot Byte -scale -outsize %d%% %d%% %s %s" % (options.gdaldir,small_scale,small_scale,tif_file,stif_file)
                run_cmd( cmd, options )

    except Usage, err:
        print >>sys.stderr, err.msg
        return 2

if __name__ == "__main__":
    sys.exit(main())
