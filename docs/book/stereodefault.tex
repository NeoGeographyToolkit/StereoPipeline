\chapter{The {\tt stereo.default} File}
\label{ch:stereodefault}

The \texttt{stereo.default} file contains configuration parameters
that the \texttt{stereo} program uses to process images.  The
\texttt{stereo.default} file is loaded from the current working
directory when you run \texttt{stereo} unless you specify a different
file using the \texttt{-s} option. Run \texttt{stereo -\/-help} for
more information. The extension is not important for this file.

A sample \texttt{stereo.default.example} file is included in the
\texttt{examples/} directory of the Stereo Pipeline software
distribution.

As mentioned in section \ref{cmdline}, all the \texttt{stereo}
parameters can also be specified on the command line.

Listed below are the parameters used by \texttt{stereo}, grouped by
processing stage.


% -------------------------------------------------------------------
%                           PREPROCESSING
% -------------------------------------------------------------------

\section{Preprocessing}
\label{stereo-default-preprocessing}
\hrule
\bigskip

\begin{description}

\item[alignment-method \textnormal{\small{(= affineepipolar, homography,
      epipolar, none)}} (default = affineepipolar)] \hfill \\

  When \texttt{alignment-method} is set to \texttt{homography},
  \texttt{stereo} will attempt to pre-align the images by
  automatically detecting tie-points between images using a feature
  based image matching technique. Tie points are stored in a
  \texttt{*.match} file that is used to compute a linear homography
  transformation of the right image so that it closely matches the
  left image.  Note: the user may exercise more control over this
  process by using the \texttt{ipfind} and \texttt{ipmatch} tools.

  When \texttt{alignment-method} is set to \texttt{affineepipolar},
  \texttt{stereo} will attempt to pre-align the images by detecting
  tie-points, as earlier, and using those to transform the images such
  that pairs of conjugate epipolar lines become collinear and parallel to
  one of the image axes.  The effect of this is equivalent to rotating the
  original cameras which took the pictures.

  When \texttt{alignment-method} is set to \texttt{epipolar},
  \texttt{stereo} will apply a 3D transform to both images so that
  their epipolar lines will be horizontal. This speeds of stereo
  correlation as it greatly reduces the area required for searching.

  {\em Epipolar alignment is only available when performing stereo
    matches using the pinhole stereo session (i.e. when using}
  \texttt{stereo -t pinhole}){\em, and cannot be used when processing
    ISIS images at this time.}

\item[left-image-crop-win \textnormal xoff yoff xsize ysize] \hfill \\
Do stereo in a sub-region of the left image [default: use the entire image].

\item[right-image-crop-win \textnormal xoff yoff xsize ysize] \hfill \\
When combined with \texttt{left-image-crop-win}, do stereo in given subregions
of left and right images. The crop windows can be determined using \texttt{stereo\_gui}.
It is important to note that when both of these
are specified, we explicitly crop the input images to these regions,
which does not happen when \texttt{left-image-crop-win} alone is specified.
In that case we use the full images but only restrict the computation
to the specified region. 

\item[force-use-entire-range \textnormal (default = false)] \hfill \\
  By default, the Stereo Pipeline will normalize ISIS images so that
  their maximum and minimum channel values are $\pm$2 standard
  deviations from a mean value of 1.0.  Use this option if you want to
  {\em disable} normalization and force the raw
  values to pass directly to the stereo correlations algorithms.

  For example, if ISIS's \texttt{histeq} has already been used to
  normalize the images, then use this option to disable normalization
  as a (redundant) pre-processing step.


\item[individually-normalize \textnormal (default = false)] \hfill \\
  By default, the maximum and minimum valid pixel value is determined
  by looking at both images.  Normalized with the same ``global'' min
  and max guarantees that the two images will retain their brightness
  and contrast relative to each other.

  This option forces each image to be normalized to its own maximum
  and minimum valid pixel value. This is useful in the event that
  images have different and non-overlapping dynamic ranges. You can
  sometimes tell when this option is needed: after a failed stereo
  attempt one of the rectified images (\texttt{*-L.tif} and
  \texttt{*-R.tif}) may be either mostly white or black.  Activating
  this option may correct this problem.

  Note: Photometric calibration and image normalization are steps that
  can and should be carried out beforehand using ISIS's own utilities.
  This provides the best possible input to the stereo pipeline and
  yields the best stereo matching results.

\item[ip-per-tile]  \hfill \\
How many interest points to detect in each $1024^2$ image tile (default: automatic
determination).

\item[ip-detect-method]  \hfill \\
What type of interest point detection algorithm to use for image alignment.
0 = Custom OBAloG implementation (default)
1 = SIFT implementation from OpenCV
2 = ORB implementation from OpenCV
If the default method does not perform well, try out one of the other two methods.

\item[epipolar-threshold]  \hfill \\
Maximum distance in pixels from the epipolar line to search for matches for each
interest point.  Due to the way ASP finds matches, reducing this value can actually
increase the number of interest points detected.  If image alignment seems to be working
well but you are not getting enough interest points to get a good search range estimate,
try setting this value to a small number, perhaps in the low double digits.

\item[ip-inlier-factor \textnormal (default = 1.0/15)] \hfill \\ A
higher factor will result in more interest points, but perhaps also
more outliers.  It is important to note that this parameter overlaps
somewhat in scope and effect with \texttt{epipolar-threshold} and
sometimes not both are active. It is suggested to experiement with both,
as well as with \texttt{ip-uniqueness-threshold} below, which has a
different justification but also somewhat similar effects.
 
\item[ip-uniqueness-threshold \textnormal (default = 0.7)] \hfill \\
A higher threshold will result in more interest points, but perhaps less unique ones.

\item[nodata-value \textnormal (default = none)] \hfill \\
Pixels with values less than or equal to this number are treated as
no-data. This overrides the nodata values from input images.

\item[datum \textnormal (default = WGS\_1984)] \hfill \\ Set the datum
to use with RPC camera models. Options: WGS\_1984, D\_MOON (1,737,400
meters), D\_MARS (3,396,190 meters), MOLA (3,396,000 meters), NAD83,
WGS72, and NAD27. Also accepted: Earth (=WGS\_1984), Mars (=D\_MARS), Moon
(=D\_MOON).

\end{description}

% -------------------------------------------------------------------
%                           CORRELATION
% -------------------------------------------------------------------


\section{Correlation}
\label{corr_section}
\hrule
\bigskip

\begin{description}

\item[prefilter-mode \textnormal{\small{(= 0,1,2,3)}} (default = 2)] \hfill \\
  This selects the pre-processing filter to be used to prepare imagery
  before it is fed to the initialization stage of the pipeline.

  \begin{description}
    \item[0 - None]
    \item[1 - Subtracted Mean] - This takes a preferably large
      Gaussian kernel and subtracts its value from the input
      image. This effectively reduces low frequency content in the
      image. The result is correlation that is immune to translations
      in image intensity.
    \item[2 - LoG Filter] - Takes the Laplacian of Gaussian of the
      image, This provides some immunity to differences in lighting
      conditions between a pair of images by isolating and matching on
      blob features in the image.
  \end{description}

  For all of the modes above, the size of the filter kernel is
  determined by the \texttt{prefilter-kernel-width} parameter below.

  The choice of pre-processing filter must be made with thought to the
  cost function being used (see \texttt{cost-mode}, below).  LoG filter
  preprocessing provides good immunity to variations in lighting
  conditions and is usually the recommended choice.

\item[prefilter-kernel-width \textnormal{\small{(\emph{float})}} (default = 1.4)] \hfill \\
  This defines the diameter of the Gaussian convolution kernel used
  for the preprocessing modes 1 and 2 above. A value of 1.4 works
  well for LoG and 25-30 works well for Subtracted Mean.

\item[corr-seed-mode \textnormal{\small{(=0,1,2,3)}}] (default = 1) \hfill \\
  This integer parameter selects a strategy for how to solve for the
  low-resolution integer correlation disparity, which is used to seed
  the full-resolution disparity later on.

  \begin{description}
  \item[0 - None] - Don't calculate a low-resolution variant of the
    disparity image. The search range provided by \texttt{corr-search}
    is used directly in computing the full-resolution disparity.

  \item[1 - Low-resolution disparity from stereo] - Calculate a
    low-resolution version of the disparity from the integer correlation
    of subsampled left and right images.  The low-resolution disparity
    will be used to narrow down the search range for the full-resolution
    disparity.

    This is a useful option despite the fact that our integer
    correlation implementation does indeed use a pyramid approach. Our
    implementation cannot search infinitely into lower resolutions due
    to its independent and tiled nature. This low-resolution disparity
    seed is a good hybrid approach.

  \item[2 - Low-resolution disparity from an input DEM] - Use a
    lower-resolution DEM together with an estimated value for its error
    to compute the low-resolution disparity, which will then be used to
    find the full-resolution disparity as above. These quantities can be
    specified via the options \texttt{disparity-estimation-dem} and
    \texttt{disparity-estimation-dem-error} respectively.

  \item[3 - Disparity from full-resolution images at a sparse number of
    points.] This is an advanced option for terrain having snow and no
    large-scale features. It is described in section \ref{sparse-disp}.

  \end{description}

  For large images, bigger than MOC-NA, using the low-resolution
  disparity seed is a definitive plus. Smaller images such as Cassini
  ISS or MER images should just shut this option off to save storage
  space.

\item[corr-sub-seed-percent \textnormal{\small{(\emph{float})}} (default=0.25)] \hfill \\
  When using \texttt{corr-seed-mode 1}, the solved-for or user-provided
  search range is grown by this factor for the purpose of computing the
  low-resolution disparity.

\item[min-num-ip \textnormal{\small{(\emph{integer})}} (default = 20)] \hfill \\
Automatic search range estimation will quit if at least this many interest points are
not detected.

\item[cost-mode \textnormal{\small{(= 0,1,2,3,4)}}] (default = 2) \hfill \\

  This defines the cost function used during integer
  correlation. Squared difference is the fastest cost
  function. However it comes at the price of not being resilient
  against noise. Absolute difference is the next fastest and is a
  better choice. Normalized cross correlation is the slowest but is
  designed to be more robust against image intensity changes and
  slight lighting differences. Normalized cross correlation is about
  2x slower than absolute difference and about 3x slower than squared
  difference.  The census transform \citep{zabih1994census} and
  ternary census transform \citep{hua2016texture} can only be used with the 
  SGM correlator.  See section \ref{sec:sgm} for details.

  \begin{description}
    \item[0 - absolute difference]
    \item[1 - squared difference]
    \item[2 - normalized cross correlation]
    \item[3 - census transform]
    \item[4 - ternary census transform]
  \end{description}

\item[corr-kernel \textnormal{\small{(\emph{integer integer})}} (default = 25 25)] \hfill \\
  These option determine the size (in pixels) of the correlation
  kernel used in the initialization step.  A different size can be set
  in the horizontal and vertical directions, but square correlation
  kernels are almost always used in practice.

\item[corr-search \textnormal{\small{(\emph{integer integer integer integer})}}] \hfill \\
  These parameters determine the size of the initial correlation
  search range.  The ideal search range depends on a variety of
  factors ranging from how the images were pre-aligned to the
  resolution and range of disparities seen in a given image pair.
  This search range is successively refined during initialization, so
  it is often acceptable to set a large search range that is guaranteed
  to contain all of the disparities in a given image.  However,
  setting tighter bounds on the search can sometimes reduce the number
  of erroneous matches, so it can be advantageous to tune the
  search range for a particular data set.

  If this option is not provided, \texttt{stereo} will make an
  attempt to guess its search range using interest points.

  These four integers define the minimum horizontal and
  vertical disparity and then the maximum horizontal and vertical
  disparity.

\item[corr-search-limit \textnormal{\small{(\emph{integer integer integer integer})}}] \hfill \\
  Set these parameters to constrain the search range that \texttt{stereo}
  automatically computes when \texttt{corr-search} is not set.
  This setting is useful when you have a good idea of the alignment quality
  in the vertical direction but not in the horizontal direction.  For example,
  when using pinhole frame cameras with epipolar alignment the actual vertical
  search range may be much smaller than the automatically computed search range.

\item[elevation-limit \textnormal{\small{(\emph{float float})}}] \hfill \\
  Notify ASP that all elevations are expected to fall in this range relative to
  the datum. Currently only used to restrict the search range estimate in 
  nadir epipolar alignment cases.

\item[xcorr-threshold \textnormal{\small{(\emph{integer})}} (default = 2)] \hfill \\

  Integer correlation to a limited sense performs a correlation
  forward and backwards to double check its result. This is one of the
  first filtering steps to insure that we have indeed converged to a
  global minimum for an individual pixel. The \texttt{xcorr-threshold}
  parameter defines an agreement threshold in pixels between the
  forward and backward result.

  Optionally, this parameter can be set to a negative number. This
  will signal the correlator to only use the forward correlation
  result. This will drastically improve speed at the cost of
  additional noise.

\item[min-xcorr-level \textnormal{\small{(\emph{integer})}} (default = 0)] \hfill \\

  When using the cross-correlation check controlled by xcorr-threshold, this parameter
  sets the minimum pyramid resolution level that the check will be performed at.  By 
  default the check will be performed at every resolution level but you may wish to increase
  this value to save time by not doubling up on processing the largest levels.
  
  Currently this feature is not enabled when using the default block-matching correlation
  method.  In that case cross correlation is only ever performed on the last resolution level.


\item[rm-quantile-percentile \textnormal{\small{(\emph{double})}} (default = 0.85)] \hfill \\
  See rm-quantile-multiple for details.

\item[rm-quantile-multiple \textnormal{\small{(\emph{double})}} (default = -1)] \hfill \\
  Used for filtering disparity values in D\_sub.  Disparities 
  greater than MULTIPLE*PERCENTILE (of the histogram) will be discarded.  
  If this value is set greater
  than zero, this filtering method will be used instead of the
  method using the values RM\_MIN\_MATCHES and RM\_THRESHOLD.
  This method will help filter out clusters of pixels which are too large to be
  filtered out by the neighborhood method but that have disparities significantly
  greater than the rest of the image.

\item[use-local-homography \textnormal (default = false)] \hfill \\

  This flag, if provided, enables using local homography during
  correlation, as described in Section \ref{sec:local_hom}.

\item[corr-timeout \textnormal{\small{(\emph{integer})}} (default = 1800)]\hfill \\

  Correlation timeout for an image tile, in seconds. A non-positive
value will result in no timeout enforcement. A value of 600 seconds
should be sufficient in most cases.

\item[stereo-algorithm \textnormal (default = 0)] \hfill \\

  Use this setting to switch between the different integer correlation options supported by ASP.  
  \begin{description}
    \item[0 - Local Search Window] - The default option searches for the best match
    for a local window around each window using the selected cost mode.  This is the 
    fastest algorithm and works well for similar images with good texture coverage.

    \item[1 - Semi-Global Matching] - Use the popular SGM algorithm \citep{hirschmuller_sgm_original}.
    This algorithm is slow and has high memory requirements but it performs better in images with
    less texture.  See section \ref{sec:sgm} for important details on using this algorithm.

    \item[2 - Smooth Semi-Global Matching] - Uses the MGM variant of the SGM algorithm 
    \citep{facciolo2015mgm} to reduce high frequency artifacts in the output image at the cost 
    of increased run time. See section \ref{sec:sgm} for important details on using this algorithm.
    
    \item[3 - MGM Final] - Use MGM on the final resolution level and SGM on preceding resolution levels.
    This produces a result somewhere in between the pure SGM and MGM options.
    
  \end{description}

\item[corr-blob-filter \textnormal{\small{(\emph{integer})}} (default = 0)]\hfill \\

  Set to apply a blob filter in each level of pyramidal integer correlation.
  When the correlator fails it often leaves "islands" of erroneous disparity results.
  Using this blob filter to remove them cleans up the final stereo output and
  can even reduce processing times by preventing the correlator from searching
  at large, incorrect disparity amounts.  The value provided is the size of blobs
  in pixels that will be removed at the full image resolution.

\item[corr-tile-size \textnormal{\small{(\emph{integer})}} (default = 1024)]\hfill \\

  Manually specifies the size of image tiles used by the correlator for multi-threaded
  processing. Typically there is no need to adjust this value but it is very important
  when using semi-global matching. See section \ref{sec:sgm} for details.  This value
  must be a multiple of 16.

\item[sgm-collar-size \textnormal{\small{(\emph{integer})}} (default = 512)]\hfill \\

  Specify the size of a region of additional processing around each correlation tile when
  using SGM or MGM processing.  This helps reduce seam artifacts at tile borders when
  processing an image that needs to be broken up into tiles at the cost of additional
  processing time.  This has no effect if the entire image can fit in one tile.

\item[sgm-search-buffer \textnormal{\small{(\emph{integer integer})}} (default = 4 4)] \hfill \\
  This option determines the size (in pixels) searches around the expected
  disparity location in successive levels of the correlation pyramid.  A smaller
  value will decrease run time and memory usage but will increase the chance of 
  blunders.  It is not reccomended to reduce either value below 2.

\item[corr-memory-limit-mb \textnormal{\small{(\emph{integer})}} (default = 6144)]\hfill \\

  Restrict the amount of memory used by the correlation step to be slightly above this value.
  This only really affects SGM/MGM which use a pair of large memory buffer in their computation.
  The total memory usage of these buffers is compared to this limit, and if it is greater then
  smaller search ranges will be used for uncertain pixels in order to reduce memory usage. If 
  the required memory is still over this limit then the program will error out. The unit is
  in megabytes.

\end{description}

% -------------------------------------------------------------------
%                           SUBPIXEL REFINEMENT
% -------------------------------------------------------------------


\section{Subpixel Refinement}
\hrule
\bigskip

\begin{description}

\item[subpixel-mode \textnormal{\small{(= 0-5)}} (default = 1)] \hfill \\
  This parameter selects the subpixel correlation method. Parabola subpixel
  is very fast but will produce results that are only slightly more accurate
   than those produced by the initialization step. Bayes EM (mode 2)
  is very slow but offers the best quality. When tuning {\tt stereo.default}
  parameters, it is expedient to start out using parabola subpixel as a
  ``draft mode.'' When the results are looking good with parabola subpixel,
  then they  will look even better with subpixel mode 2.  For inputs with
  little noise, the affine method (subpixel mode 3) may produce results
  equivalent to Bayes EM in a shorter time.
  
  Subpixel modes 4 and 5 are experimental.  Modes 6 and up are only used to
  override the default subpixel method used when performing SGM or MGM 
  correlation.  The default subpixel method for SGM/MGM is a custom 
  algorithm that should work well but the Cosine algorithm also works well.

  \begin{description}
    \item[0 - no subpixel refinement]
    \item[1 - parabola fitting ]
    \item[2 - affine adaptive window, Bayes EM weighting ]
    \item[3 - affine window ]
    \item[4 - Lucas-Kanade method (experimental)]
    \item[5 - affine adaptive window, Bayes EM with Gamma Noise Distribution (experimental) ]
    \item[6 - SGM linear ]
    \item[7 - SGM Poly4 ]
    \item[8 - SGM Cosine ]
    \item[9 - SGM Parabola ]
    \item[10 - SGM None ]
    \item[10 - SGM Blend ]
  \end{description}

  For a visual comparison of the quality of these subpixel modes,
  refer back to Chapter:\ref{ch:correlation}.

\item[subpixel-kernel \textnormal{\small{(\emph{integer integer})}} (default = 35 35)]
  Specify the size of the horizontal and vertical size (in pixels) of
  the subpixel correlation kernel. It is advantageous to keep this
  small for parabola fitting in order to resolve finer
  details. However for the Bayes EM methods, keep the kernel slightly
  larger. Those methods weight the kernel with a Gaussian
  distribution, thus the effective area is small than the kernel size
  defined here.

\end{description}

% -------------------------------------------------------------------
%                           FILTERING
% -------------------------------------------------------------------

\section{Filtering}
\label{filter_options}

\hrule
\bigskip

\begin{description}

\item[filter-mode \textnormal{\small{(\emph{integer})}} (default = 1)]
\hfill \\ This parameter sets the filter mode. Three modes are supported
as described below. Here, by neighboring pixels for a current pixel we
mean those pixels within the window of half-size of
\texttt{rm-half-kernel} centered at the current pixel.
  \begin{description}
    \item[0] - No filtering.
    \item[1] - Filter by discarding pixels at which disparity differs from mean disparity of neighbors by more than \texttt{max-mean-diff}.
    \item[2] - Filter by discarding pixels at which percentage of neighboring disparities that are within \texttt{rm-threshold} of current disparity is less than \texttt{rm-min-matches}.
  \end{description}

\item[rm-half-kernel \textnormal{\small{(\emph{integer integer})}} (default = 5 5)] \hfill \\
  This setting adjusts the behavior of an outlier rejection scheme
  that ``erodes'' isolated regions of pixels in the disparity map that
  are in disagreement with their neighbors.

  The two parameters determine the size of the half kernel that is
  used to perform the automatic removal of low confidence pixels.  A
  $5 \times 5$ half kernel would result in an $11 \times 11$ kernel
  with 121 pixels in it.

\item[max-mean-diff \textnormal{\small{(\emph{integer})}} (default = 3)] \hfill \\
  This parameter sets the {\em maximum difference} between the current pixel disparity and the mean of disparities of neighbors in order for a
  given disparity value to be retained (for \texttt{filter-mode} 1).

\item[rm-min-matches \textnormal{\small{(\emph{integer})}} (default = 60)] \hfill \\
  This parameter sets the {\em percentage} of neighboring disparity
  values that must fall within the inlier threshold in order for a
  given disparity value to be retained (for \texttt{filter-mode} 2).

\item[rm-threshold \textnormal{\small{(\emph{integer})}} (default = 3)] \hfill \\
  This parameter sets the inlier threshold for the outlier rejection
  scheme.  This option works in conjunction with RM\_MIN\_MATCHES
  above.  A disparity value is rejected if it differs by more than
  RM\_THRESHOLD disparity values from RM\_MIN\_MATCHES percent of
  pixels in the region being considered  (for \texttt{filter-mode} 2).

\item[rm-cleanup-passes \textnormal{\small{(\emph{integer})}} (default = 1)] \hfill \\
  Select the number of outlier removal passes that are carried out.
  Each pass will erode pixels that do not match their neighbors.  One
  pass is usually sufficient.

\item[median-filter-size \textnormal{\small{(\emph{integer})}} (default = 0)] \hfill \\
  Apply a median filter of the selected kernel size to the subpixel disparity results.
  This option can only be used if \texttt{rm-cleanup-passes} is set to zero.

\item[texture-smooth-size \textnormal{\small{(\emph{integer})}} (default = 0)] \hfill \\
  Apply an adaptive filter to smooth the disparity results inversely proportional to
  the amount of texture present in the input image.  This value sets the maximum size 
  of the smoothing kernel used (in pixels).
  This option can only be used if \texttt{rm-cleanup-passes} is set to zero.

\item[texture-smooth-scale \textnormal{\small{(\emph{float})}} (default = 0.15)] \hfill \\
  Used in conjunction with \texttt{texture-smooth-size}, this value helps control the 
  regions of the image that will be smoothed.  A larger value will result in more 
  smoothing being applied to more of the image.  A smaller value will leave high-texture
  regions of the image unsmoothed.

\item[enable-fill-holes (default = false)] \hfill \\

Enable filling of holes in disparity using an inpainting
method. Obsolete. It is suggested to use instead point2dem's analogous
functionality.

\item[fill-holes-max-size \textnormal{\small{(\emph{integer})}} (default = 100,000)] \hfill \\
  Holes with no more pixels than this number should be filled in.
\item[edge-buffer-size \textnormal{\small{(\emph{integer})}} (default = -1)] \hfill \\
  Crop to be applied around image borders during filtering.  If not set, default to subpixel kernel size.
\item[erode-max-size \textnormal{\small{(\emph{integer})}} (default = 0)] \hfill \\
  Isolated blobs with no more pixels than this number should be removed.

\end{description}

% -------------------------------------------------------------------
%                           POST_PROCESSING
% -------------------------------------------------------------------

\section{Post-Processing (Triangulation)}
\label{triangulation_options}
\hrule
\bigskip

\begin{description}
\item[near-universe-radius \textnormal{\small{(\emph{float})}} (default = 0.0)]
\item[far-universe-radius \textnormal{\small{(\emph{float})}} (default = 0.0)] \hfill \\

These parameters can be used to remove outliers from the 3D triangulated
point cloud. The points that will be kept are those whose distance from
the universe center (see below) is between \texttt{near-universe-radius}
and \texttt{far-universe-radius}, in meters.

\item[universe-center \textnormal (default = none)] \hfill \\
Defines the reference location to use when filtering the output point cloud
using the above near and far radius options. The available options
are:

  \begin{description}
    \item[None] - Disable filtering.
    \item[Camera] - Use the left camera's center as the universe center.
    \item[Zero]   - Use the center of the planet as the universe center.
  \end{description}

\item[bundle-adjust-prefix \textnormal{\small{(\emph{string})}}] \hfill \\ Use the camera adjustments obtained by previously running bundle\_adjust with this output prefix.

\item[min-triangulation-angle \textnormal{\small{(\emph{double})}}] \hfill \\
The minimum angle, in degrees, at which rays must meet at a triangulated
point to accept this point as valid. The internal default is somewhat
less than 1 degree.

\item[point-cloud-rounding-error \textnormal{\small{(\emph{double})}}] \hfill \\

How much to round the output point cloud values, in meters (more
rounding means less precision but potentially smaller size on disk). The
inverse of a power of 2 is suggested. Default: $1/2^{10}$ meters (about 1mm) for Earth and
proportionally less for smaller bodies.

\item[save-double-precision-point-cloud \textnormal (default = false)] \hfill \\

Save the final point cloud in double precision rather than bringing the
points closer to origin and saving as float (marginally more precision
at twice the storage).

\item[compute-error-vector \textnormal (default = false)] \hfill \\

When writing the output point cloud, save the 3D triangulation error
vector (the vector between the closest points on the rays emanating from
the two cameras), rather than just its length. In this case, the point
cloud will have 6 bands (storing the triangulation point and
triangulation error vector) rather than the usual 4. When invoking
\texttt{point2dem} on this 6-band point cloud and specifying the
\texttt{-\/-errorimage} option, the error image will contain the three
components of the triangulation error vector in the North-East-Down
coordinate system.

The next several parameters are used for jitter correction for Digital
Globe imagery. A usage tutorial is given in section \ref{sec:jitter}.

\item[image-lines-per-piecewise-adjustment \textnormal{\small{(\emph{integer})}} (default = 0)]
A positive value, e.g., 1000, will turn on using piecewise camera adjustments to help reduce jitter effects. Use one adjustment per this many image lines.

\item[piecewise-adjustment-percentiles \textnormal{\small{(\emph{float
        float})}} (default = 5 95)]
A narrower range will place the piecewise adjustments for jitter correction closer together and further from the first and last lines in the image.

\item[piecewise-adjustment-interp-type \textnormal{\small{(\emph{integer})}} (default = 1)]
How to interpolate between adjustments. [1 Linear, 2 Using Gaussian weights]

\item[piecewise-adjustment-camera-weight \textnormal{\small{(\emph{float})}} (default = 1.0)]
The weight to use for the sum of squares of adjustments component of the cost function. Increasing this value will constrain the adjustments to be smaller.

\item[num-matches-for-piecewise-adjustment \textnormal{\small{(\emph{integer})}} (default = 90000)]
How many matches among images to create based on the disparity for the purpose of solving for jitter using piecewise adjustment.

These last two options are used internally.

\item[compute-piecewise-adjustments-only \textnormal (default = false)] \hfill \\
Compute the piecewise adjustments as part of jitter correction, and then stop.

\item[skip-computing-piecewise-adjustments \textnormal (default = false)] \hfill \\
Skip computing the piecewise adjustments for jitter, they should have been done by now.

\end{description}
